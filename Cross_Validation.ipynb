{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mUvivf76iKuU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
      ],
      "metadata": {
        "id": "uZc47QVMlg3i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert from pandas dataframe to tensor\n",
        "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
        "\n",
        "# transform species to number\n",
        "labels = torch.zeros(len(data), dtype=torch.long)\n",
        "# labels[iris.species=='setosa'] = 0 # don't need!\n",
        "labels[iris.species=='versicolor'] = 1\n",
        "labels[iris.species=='virginica'] = 2\n",
        ""
      ],
      "metadata": {
        "id": "TxbAx7ZTl75X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
        "fakelabels = np.arange(10)>4\n",
        "print(fakedata), print(' ')\n",
        "print(fakelabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKS5xN-KmVyW",
        "outputId": "6d62d2e7-b5d1-425e-de19-4d3fef9e84e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 11  12  13  14]\n",
            " [ 21  22  23  24]\n",
            " [ 31  32  33  34]\n",
            " [ 41  42  43  44]\n",
            " [ 51  52  53  54]\n",
            " [ 61  62  63  64]\n",
            " [ 71  72  73  74]\n",
            " [ 81  82  83  84]\n",
            " [ 91  92  93  94]\n",
            " [101 102 103 104]]\n",
            " \n",
            "[False False False False False  True  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fakedataLdr = DataLoader(fakedata, shuffle=True)\n",
        "print( fakedataLdr )\n",
        "print( fakedataLdr.batch_size )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu1hA0vLpJ2u",
        "outputId": "1da18675-82cd-4a1b-add3-97300517ca24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7dec67ba3bd0>\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,oneSample in enumerate(fakedataLdr):\n",
        "  print(i,oneSample,oneSample.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPefCc8fpMOy",
        "outputId": "23e5aa6d-56a1-4013-d816-d0d7bc60b5aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([[101, 102, 103, 104]]) torch.Size([1, 4])\n",
            "1 tensor([[71, 72, 73, 74]]) torch.Size([1, 4])\n",
            "2 tensor([[91, 92, 93, 94]]) torch.Size([1, 4])\n",
            "3 tensor([[81, 82, 83, 84]]) torch.Size([1, 4])\n",
            "4 tensor([[51, 52, 53, 54]]) torch.Size([1, 4])\n",
            "5 tensor([[31, 32, 33, 34]]) torch.Size([1, 4])\n",
            "6 tensor([[61, 62, 63, 64]]) torch.Size([1, 4])\n",
            "7 tensor([[21, 22, 23, 24]]) torch.Size([1, 4])\n",
            "8 tensor([[11, 12, 13, 14]]) torch.Size([1, 4])\n",
            "9 tensor([[41, 42, 43, 44]]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fakeDataset = torch.utils.data.TensorDataset(torch.Tensor(fakedata),torch.Tensor(fakelabels))\n",
        "print( fakeDataset.tensors ), print(' ')\n",
        "fakedataLdr = DataLoader(fakeDataset, shuffle=True)\n",
        "for dat,lab in fakedataLdr:\n",
        "  print(dat,lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUY-Z-j9pPJY",
        "outputId": "89ad7e2f-993d-4949-d4dc-c0ba158a02f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 11.,  12.,  13.,  14.],\n",
            "        [ 21.,  22.,  23.,  24.],\n",
            "        [ 31.,  32.,  33.,  34.],\n",
            "        [ 41.,  42.,  43.,  44.],\n",
            "        [ 51.,  52.,  53.,  54.],\n",
            "        [ 61.,  62.,  63.,  64.],\n",
            "        [ 71.,  72.,  73.,  74.],\n",
            "        [ 81.,  82.,  83.,  84.],\n",
            "        [ 91.,  92.,  93.,  94.],\n",
            "        [101., 102., 103., 104.]]), tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]))\n",
            " \n",
            "tensor([[21., 22., 23., 24.]]) tensor([0.])\n",
            "tensor([[91., 92., 93., 94.]]) tensor([1.])\n",
            "tensor([[31., 32., 33., 34.]]) tensor([0.])\n",
            "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
            "tensor([[101., 102., 103., 104.]]) tensor([1.])\n",
            "tensor([[11., 12., 13., 14.]]) tensor([0.])\n",
            "tensor([[71., 72., 73., 74.]]) tensor([1.])\n",
            "tensor([[81., 82., 83., 84.]]) tensor([1.])\n",
            "tensor([[41., 42., 43., 44.]]) tensor([0.])\n",
            "tensor([[61., 62., 63., 64.]]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
        "train_data = torch.utils.data.TensorDataset(\n",
        "     torch.Tensor(train_data),torch.Tensor(train_labels))\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(\n",
        "     torch.Tensor(test_data),torch.Tensor(test_labels))\n",
        "train_loader = DataLoader(train_data,batch_size=4)\n",
        "test_loader  = DataLoader(test_data)"
      ],
      "metadata": {
        "id": "7nDRZyNmpV65"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAINING DATA')\n",
        "for batch,label in train_loader: # iterable\n",
        "  print(batch,label)\n",
        "  print(' ')\n",
        "\n",
        "\n",
        "print(' ')\n",
        "print('TESTING DATA')\n",
        "for batch,label in test_loader: # iterable\n",
        "  print(batch,label)\n",
        "  print(' ')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh7vFp2QpaU-",
        "outputId": "0e511042-610b-49bd-a401-964c57d066aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "tensor([[51., 52., 53., 54.],\n",
            "        [81., 82., 83., 84.],\n",
            "        [31., 32., 33., 34.],\n",
            "        [71., 72., 73., 74.]]) tensor([0., 1., 0., 1.])\n",
            " \n",
            "tensor([[ 21.,  22.,  23.,  24.],\n",
            "        [ 11.,  12.,  13.,  14.],\n",
            "        [ 41.,  42.,  43.,  44.],\n",
            "        [101., 102., 103., 104.]]) tensor([0., 0., 0., 1.])\n",
            " \n",
            " \n",
            "TESTING DATA\n",
            "tensor([[61., 62., 63., 64.]]) tensor([1.])\n",
            " \n",
            "tensor([[91., 92., 93., 94.]]) tensor([1.])\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use scikitlearn to split the data\n",
        "train_data,test_data, train_labels,test_labels = \\\n",
        "                              train_test_split(data, labels, train_size=.8)\n",
        "\n",
        "\n",
        "# then convert them into PyTorch Datasets (note: already converted to tensors)\n",
        "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
        "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
        "\n",
        "\n",
        "# finally, translate into dataloader objects\n",
        "train_loader = DataLoader(train_data,shuffle=True,batch_size=12)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
      ],
      "metadata": {
        "id": "tFkEQjlCpc6E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createANewModel():\n",
        "\n",
        "  # model architecture\n",
        "  ANNiris = nn.Sequential(\n",
        "      nn.Linear(4,64),   # input layer\n",
        "      nn.ReLU(),         # activation unit\n",
        "      nn.Linear(64,64),  # hidden layer\n",
        "      nn.ReLU(),         # activation unit\n",
        "      nn.Linear(64,3),   # output units\n",
        "        )\n",
        "\n",
        "  # loss function\n",
        "  lossfun = nn.CrossEntropyLoss()\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = torch.optim.SGD(ANNiris.parameters(),lr=.01)\n",
        "\n",
        "  return ANNiris,lossfun,optimizer\n",
        ""
      ],
      "metadata": {
        "id": "xFddthPLpgIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numepochs = 500\n",
        "\n",
        "def trainTheModel():\n",
        "\n",
        "  # initialize accuracies as empties (not storing losses here)\n",
        "  trainAcc = []\n",
        "  testAcc  = []\n",
        "\n",
        "  # loop over epochs\n",
        "  for epochi in range(numepochs):\n",
        "\n",
        "\n",
        "    # loop over training data batches\n",
        "    batchAcc = []\n",
        "    for X,y in train_loader:\n",
        "\n",
        "      # forward pass and loss\n",
        "      yHat = ANNiris(X)\n",
        "      loss = lossfun(yHat,y)\n",
        "\n",
        "      # backprop\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # compute training accuracy just for this batch\n",
        "      batchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
        "    # end of batch loop...\n",
        "\n",
        "\n",
        "    # now that we've trained through the batches, get their average training accuracy\n",
        "    trainAcc.append( np.mean(batchAcc) )\n",
        "\n",
        "    # test accuracy\n",
        "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
        "    predlabels = torch.argmax( ANNiris(X),axis=1 )\n",
        "    testAcc.append( 100*torch.mean((predlabels == y).float()).item() )\n",
        "\n",
        "  # function output\n",
        "  return trainAcc,testAcc\n",
        "\n"
      ],
      "metadata": {
        "id": "NLguqCgvpmVy"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}